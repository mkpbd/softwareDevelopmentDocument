
https://github.com/Devinterview-io/databases-interview-questions
https://github.com/Devinterview-io/t-sql-interview-questions

## Explain the ACID properties in the context of databases

Sure! ACID properties are a set of principles that ensure reliable processing of database transactions. Here's an easy way to understand them:

1. **Atomicity**:
    
    - **All or Nothing**: A transaction must be fully completed or not done at all. If any part of the transaction fails, the whole transaction is rolled back, leaving the database unchanged.
    - **Example**: If you are transferring money between two bank accounts, either both the withdrawal and the deposit occur, or neither does.
2. **Consistency**:
    
    - **Validity**: A transaction must take the database from one valid state to another, maintaining database rules (constraints, triggers, etc.).
    - **Example**: If a database rule states that the balance of a bank account cannot be negative, a transaction that results in a negative balance will be aborted.
3. **Isolation**:
    
    - **Independence**: Transactions should not interfere with each other. The result should be as if transactions were executed one after another, even if they are run concurrently.
    - **Example**: If two people are transferring money simultaneously, the transactions should not mix up the balances.
4. **Durability**:
    
    - **Permanence**: Once a transaction is committed, it will remain so, even in the event of a system failure. The changes are saved permanently.
    - **Example**: After you transfer money and receive a confirmation, the new balances are safely stored and won't disappear if the system crashes.

These properties help ensure the reliability and integrity of transactions within a database.

### ACID in Practical Scenarios

1. **Banking Applications**: ACID ensures that monetary transactions are secure and reliable.
    
2. **Inventory Management**: When goods are purchased, inventory levels are updated consistently, without corruption or errors.
    
3. **Scheduling Systems**: Activities, such as booking appointments, either take place entirely or not at all, avoiding messy partial bookings.
    
4. **E-commerce Order Processing**: The entire cycle, from a customer placing an order to its fulfilment, is a cohesive and consistent unit of work.
    
5. **Messaging Services**: For example, ensuring that a message is sent only after it is completely composed, not mid-way.

## What is _database normalization_, and why do we use it?

**Database normalization** is a set of practices that ensure **data integrity** by minimizing redundancy and dependency within a relational database.

### Advantages of Normalization


1. **Data Consistency**: Reduction in redundancy decreases the risk of inconsistent data.
2. **Improved Maintainability**: With a more structured database, maintenance becomes more straightforward.
3. **Easier Updates**: Normalization usually means fewer records to update.

### Normalization Levels

There are generally six levels of normalization, from 0 to 5 or "BCNF".
#### First Normal Form (1NF)

1. **Unique Primary Keys**: A table should have a unique primary key for each record.
2. **Atomic Values**: Each cell in a table should hold a single value, eliminating multi-valued attributes.
#### Second Normal Form (2NF)

- All requirements of the previous form, as well as:
- Removal of **Partial Dependencies**: Non-primary key columns should depend on the entire primary key.

#### Third Normal Form (3NF)


- All requirements of 2NF, as well as:
- Elimination of **Transitive Dependencies**: Non-primary key columns should not be dependent on other non-primary key columns.

#### Boyce-Codd Normal Form (BCNF)

- A stricter version of 3NF that ensures each determinant is a candidate key.

#### Fourth Normal Form (4NF)



- Deals with multi-valued dependencies.

#### Fifth Normal Form (5NF)


- Also called "Projection-Join Normal Form" and deals with join dependencies.

### Normal Forms and Use-Cases


Most relational databases aim for 3NF, as it typically strikes a good balance between performance and data integrity.

However, it's essential to understand the specific **requirements** of your database and decide on an optimal normalization level accordingly. For instance, reporting databases might not be heavily normalized to improve query performance.

## Describe a _relational database schema_.

A **Relational Database Schema** is a set of rules that define the structure, constraints, and relationships of data tables in a **Relational Database Management System (RDBMS)**.

### Core Components
1. **Tables**: Central data containers often referred to as "relations."
    - Defined by column names and data types.
2. **Columns**: Attributes or fields, defined by their name, type, and optional constraints.
    - Each column should have a unique name within the table.
    - Common data types include integers, strings, dates, and more.
3. **Rows**: Individual data records, consisting of data based on the table's defined columns.
    - Each row should have a unique identifier, often referred to as a "primary key".

### Key Types

1. **Primary Key (PK)**: A unique identifier for each record within a table. It's often an auto-incrementing integer. Each table should have precisely one primary key. This is Essential designated as “E” in databases.
2. **Foreign Key (FK)**: A field or a group of fields in a table that uniquely identifies a row in another table. Commonly a primary key from another table, these help establish relationships between tables. This term is derived as “F” from Candidate Key in databases
### Relationship Types

1. **One-to-One**: Each record in the first table is related to one and only one record in the second table, and vice versa.
2. **One-to-Many**: A record in the first table can be related to one or more records in the second table, but a record in the second table is related to only one record in the first table.
3. **Many-to-Many**: Records in both tables can be related to multiple records in the other table. This relationship requires a linking table.

### Common Constraints

- **NOT NULL**: Specifying that a column must have a value and cannot be left empty. This is Essential designated as “E” in databases.
- **UNIQUE**: Requires all entries in a column or set of columns to be distinct.
- **CHECK**: Allows for conditional checks to be applied to column data.
- **DEFAULT**: Automatically provides a predetermined value when a new column is created.
- **INDEX**: Optimizes data retrieval by creating an index on the column(s), speeding up relevant queries.
## 14. Explain the function of _GROUP BY_ and _HAVING_ clauses in SQL.

**GROUP BY** and **HAVING** transform, filter, and work together with aggregate functions to enable more complex and nuanced result sets.

### Functions of GROUP BY


- **Aggregation**: Identifies groups and computes aggregate functions (e.g., COUNT, SUM) for each group.
- **Redundancy Reduction**: Collapses redundant data based on the grouped columns to provide a leaner dataset.
- **Column Constraint**: Allows queries to select only aggregated columns, and from the source columns, all non-aggregated ones need to be in the `GROUP BY`, ensuring consistent data representation.

### Functions of HAVING


- **Group-Wise Filtering**: Applies conditional checks to grouped data.
- **Post-Group Filtering**: Allows filtering based on the results of aggregate functions.
- **Aggregation Assertion**: Validates aggregated values against specific conditions.
- **Comparison with WHERE**: Enables more advanced, aggregate-aware filtering compared to the global, pre-aggregation filtering provided by `WHERE`.

### Code Example: GROUP BY & HAVING

Consider the following relational schema:

```sql
EMPLOYEE (ID, Name, DeptID, Salary)
DEPARTMENT (ID, Name)
```
To retrieve department IDs where the average salary is over a certain threshold:

#### SQL Query
```sql

SELECT DeptID
FROM EMPLOYEE
GROUP BY DeptID
HAVING AVG(Salary) > 50000;
```

## 15. What are _indexes_ and how do they work in databases?

An **index** serves as a data structure in a database system. It enhances the efficiency and speed of data lookup operations by logically ordering the indexed data.

### Index Types

- **B-Tree (Balanced Tree)**: Suited for ranges and equality operations, such as using `WHERE` clauses in SQL.
- **Hash**: Ideal for exact-match lookups, like primary keys.
- **Full-text**: Specifically designed for text searches, often seen in search engines.
- **Bitmap**: Efficient for low-cardinality columns, where there are few distinct values, like gender.

### Data Lookup Using Indexes


- **Ordered Scans**: Possible through B-Tree indexes where data is sorted, aiding range queries.
- **Exact-Match Sequencing**: For Hash and tree-based indexes, this ensures swift exact-value matches.
- **Range Searches**: Supported by B-Trees, they enable operations like finding numbers within a range.

### Best Practices


- **Consider Index Maintenance Overhead**: While indexes speed up reads, they might slow down data modifications like `INSERT`, `UPDATE`, and `DELETE`.
- **Index Tailing**: Place more selective columns first, and follow them with less-discriminatory columns for best results.
- **Index Coverage**: Aim to cover frequently queried columns, but don't go overboard, leading to index bloat.

### Code Example: Index Types in PostgreSQL

```sql
-- B-Tree Index
CREATE INDEX idx_btree ON table_name (column_name);

-- Hash Index
CREATE INDEX idx_hash ON table_name USING HASH (column_name);
```

